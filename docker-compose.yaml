version: "3"

services:
  oracle:
    image: banglamon/oracle193db:19.3.0-ee
    tty: true
    restart: always
    ports:
      - "1521:1521"
    environment:
      - ORACLE_SID=MORAL
      - ORACLE_PDB=MORALPDB
      - ORACLE_PWD=Oracle123
    volumes:
       
      -  /home/pedro/Develop/estudos/kafka/kafkaconnect-mysql-elasticsearch/oracle/oradata:/opt/oracle/oradata
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    user: root
    environment:
      ZOOKEEPER_CLIENT_PORT: 1521

  mysql:
    image: wesleywillians/mysql-kafka-connect:latest
    command: --innodb-use-native-aio=0
    tty: true
    restart: always
    ports:
      - "33600:3306"
    environment:
      - MYSQL_DATABASE=products
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_USER=root
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    user: root
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://host.docker.internal:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  control-center:
    image: confluentinc/cp-enterprise-control-center:6.0.1
    hostname: control-center
    user: root
    depends_on:
      - kafka
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_CONNECT_CLUSTER: http://kafka-connect:8083
      PORT: 9021
    extra_hosts:
      - "host.docker.internal:172.17.0.1"


  kafka-connect:
    image: confluentinc/cp-kafka-connect-base:6.0.0
    container_name: kafka-connect
    user: root
    depends_on:
      - zookeeper
      - kafka
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      # # Optional settings to include to support Confluent Control Center
      #   CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      #   CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      #  ---------------
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
    # If you want to use the Confluent Hub installer to d/l component, but make them available
    # when running this offline, spin up the stack once and then run :
    #   docker cp kafka-connect:/usr/share/confluent-hub-components ./data/connect-jars
    volumes:
      - $PWD/data:/data
    # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
    command:
      - bash
      - -c
      - |
        echo "Installing Connector"
        sudo yum install java-1.8.0-openjdk-devel
        sudo yum install java-1.8.0-openjdk
        
        source ~/.bash_profile
        yum install --nogpgcheck maven -y
        yum update
        yum upgrade
        wget http://mirror.centos.org/centos/8/BaseOS/x86_64/os/Packages/ppp-2.4.7-26.el8_1.x86_64.rpm
        rpm -i ppp-2.4.7-26.el8_1.x86_64.rpm 
        dnf install ppp
        wget https://software.sonicwall.com/NetExtender/NetExtender.Linux-10.2.826-1.x86.64.rpm
        rpm -i NetExtender.Linux-10.2.826-1.x86.64.rpm 
        mknod /dev/ppp c 108 0
        confluent-hub install confluentinc/kafka-connect-jdbc:latest
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:1.2.2
        wget https://github.com/thake/logminer-kafka-connect/releases/download/0.6.3/thake-logminer-kafka-connect-0.6.3.zip
        confluent-hub install ./thake-logminer-kafka-connect-0.6.3.zip --no-prompt
        rm ./thake-logminer-kafka-connect-0.6.3.zip
        cd /usr/share/java/
        yum install git -y
        git clone https://github.com/PedroPCardoso/docker-kakfa-oracle.git
        cp /usr/share/java/docker-kakfa-oracle/ojdbc8-full/*.jar  /usr/share/java/
        chmod 644 *.jar
        cd /usr/share/confluent-hub-components/thake-logminer-kafka-connect/lib/
        git clone https://github.com/PedroPCardoso/docker-kakfa-oracle.git
        cp /usr/share/confluent-hub-components/thake-logminer-kafka-connect/lib/docker-kakfa-oracle/ojdbc8-full/*.jar  /usr/share/confluent-hub-components/thake-logminer-kafka-connect/lib/
        chmod 644 *.jar
        export CLIENT_HOME=/usr/lib/oracle/18.3/client64
        export LD_LIBRARY_PATH=$CLIENT_HOME/lib
        export PATH=$PATH:$CLIENT_HOME/bin
        cd /home/appuser
        wget https://download.oracle.com/otn_software/linux/instantclient/211000/instantclient-basic-linux.x64-21.1.0.0.0.zip
        wget https://download.oracle.com/otn_software/linux/instantclient/211000/instantclient-sqlplus-linux.x64-21.1.0.0.0.zip
        yum install unzip -y
        unzip instantclient-basic-linux.x64-21.1.0.0.0.zip
        unzip instantclient-sqlplus-linux.x64-21.1.0.0.0.zip
        echo 'export LD_LIBRARY_PATH=/home/appuser/instantclient_21_1' >> ~/.bash_profile
        echo 'export PATH=$PATH:$LD_LIBRARY_PATH' >> ~/.bash_profile
        export LD_LIBRARY_PATH=/home/appuser/instantclient_21_1
        export PATH=$PATH:$LD_LIBRARY_PATH
        source ~/.bash_profile
        cd /home/appuser/
        wget http://software.sonicwall.com/NetExtender/NetExtender.Linux-10.2.826.x86_64.tgz
        tar zxvf NetExtender.Linux-10.2.826.x86_64.tgz
        cd netExtenderClient/

        yum install nano -y
        yum install libaio -y
        yum install libstdc++.so.6 -y
        yum install libc.so.6 -y
        yum install libgcc_s.so.6 -y
        ln -sf /usr/lib64/libnsl.so.2 libnsl.so.1
        confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:11.0.3
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        sleep infinity
    extra_hosts:
      - "host.docker.internal:172.17.0.1"
      - "host.oracle.internal:192.168.1.250"


  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.11.2
    container_name: es01
    environment:
      - node.name=es01
      - discovery.type=single-node
      # - cluster.name=es-docker-cluster
      # - cluster.initial_master_nodes=es01
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./es01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  kib01:
    image: docker.elastic.co/kibana/kibana:7.11.2
    user: root
    container_name: kib01
    ports:
      - 5601:5601
    environment:
      ELASTICSEARCH_URL: http://es01:9200
      ELASTICSEARCH_HOSTS: '["http://es01:9200"]'
    extra_hosts:
      - "host.docker.internal:172.17.0.1"
